### Questions
* Should we fillna inside or outside CV loop?
* Are we allowed to use X_new to train on? (KNN fillna, etc.)


### Ideas
Missing vals
* If we just take mean, probably standardize first (cuz of std)


Data clean / visualize
* Categorical variables: One-hot-encoding
* Compute the covariance matrix
* PCA / SVD
* Throw out useless variables

Models2
* Other points
    * Hyper parameter tuning
    * How many PCs?
    * Squared variables (basis expansion)
* Models
    * KNN
    * Random forest
        * No need for PCA

Workflows (final models)
* (Std + PCA) + basis exp + ElasticNet
* (Basis exp) + Random Forest
* KernelSVM


Model selection
* Find out which coeff lasso (etc.) uses 
* AIC = leave-one-out-ish (BIC only for n>>p)


Optimize models
* Weight tuning: Bagging

Error estimation + Hyper parameters
* Double nested leave-one-out (validation + test)
    * Inner LOO: (val + train) to determine hyperparamters
    * Outer LOO: (valtrain + test) to determine error